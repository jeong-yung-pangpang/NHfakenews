# -*- coding: utf-8 -*-
"""RogisticRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1caahT299AedX-V6POXxH-XkK3zPCFR-5
"""

import pandas as pd
import numpy as np

from google.colab import drive
drive.mount('/content/drive')
Train = pd.read_csv('/content/drive/MyDrive/datasets/news_train.csv')
Test = pd.read_csv('/content/drive/MyDrive/datasets/news_test.csv')

import re

train_df = Train.fillna(' ')
# 정규 표현식을 이용해 숫자를 공백으로 변경(정규 표현식으로 \d는 숫자를 의미함.)
train_df['content'] = train_df['content'].apply(lambda x : re.sub(r"\d+", " ", x))

# 테스트 데이터도 동일하게 Null 및 숫자를 공백으로 변환
test_df = Test.fillna(' ')
test_df['content'] = test_df['content'].apply(lambda x : re.sub(r"\d+", " ", x))

from sklearn.model_selection import train_test_split

X_features = train_df['content']
y_label = Train['info']
# 전체 Train 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출
X_train, X_test, y_train, y_test = train_test_split(X_features, y_label, test_size=0.2, random_state=156)
print(X_train.shape, X_test.shape)

from konlpy.tag import Twitter

twitter = Twitter()
def tw_tokenizer(text):
  # 입력 인자로 들어온 텍스트를 형태소 단어로 토큰화해 리스트 형태로 반환
  tokens_ko = twitter.morphs(text)
  return tokens_ko

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# Twitter 객체의 morphs() 객체를 이용한 tokenizer를 사용. ngram_range는 (1,2)
tfidf_vect = TfidfVectorizer(tokenizer=tw_tokenizer, ngram_range=(1,2), min_df=3, max_df=0.9)
tfidf_vect.fit(X_train)
tfidf_matrix_train = tfidf_vect.transform(X_train)

# 로지스틱 회귀를 이용해 분류 수행
lg_clf = LogisticRegression(random_state=0)

# 파라미터 C 최적화를 위해 GridSearchCV를 이용
params = {'C':[1, 3.5, 4.5, 5.5, 10]}
grid_cv = GridSearchCV(lg_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)
grid_cv.fit(tfidf_matrix_train, y_train)
print(grid_cv.best_params_, round(grid_cv.best_score_, 4))

from sklearn.metrics import accuracy_score

# 학습 데이터를 적용한 TfidfVectorizer를 이용해 테스트 데이터를 TF-IDF 값으로 피처 변환함
tfidf_matrix_test = tfidf_vect.transform(X_test)

# classifier는 GridSearchCV에서 최적 파라미터로 학습된 classifier를 그대로 이용
best_estimator = grid_cv.best_estimator_
preds = best_estimator.predict(tfidf_matrix_test)

print('Logistic Regression 정확도: ', accuracy_score(y_test, preds))

real_test_x = test_df['content']
tfidf_matrix_test = tfidf_vect.transform(real_test_x)

pred_test = best_estimator.predict(tfidf_matrix_test)
pred_test

sample_submission = pd.read_csv('/content/drive/MyDrive/datasets/sample_submission.csv')

sample_submission.loc[:,'info'] = np.where(pred_test> 0.5, 1,0).reshape(-1)
sample_submission.loc[:,["id","info"]].to_csv("LogisticRegression.csv", index = False)
sample_submission